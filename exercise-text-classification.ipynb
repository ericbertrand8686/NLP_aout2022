{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53790d2c",
   "metadata": {
    "papermill": {
     "duration": 0.016707,
     "end_time": "2021-11-09T00:09:38.658588",
     "exception": false,
     "start_time": "2021-11-09T00:09:38.641881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**This notebook is an exercise in the [Natural Language Processing](https://www.kaggle.com/learn/natural-language-processing) course.  You can reference the tutorial at [this link](https://www.kaggle.com/matleonard/text-classification).**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6eecfa",
   "metadata": {
    "papermill": {
     "duration": 0.016135,
     "end_time": "2021-11-09T00:09:38.690050",
     "exception": false,
     "start_time": "2021-11-09T00:09:38.673915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Natural Language Classification\n",
    "\n",
    "You did such a great job for DeFalco's restaurant in the previous exercise that the chef has hired you for a new project.\n",
    "\n",
    "The restaurant's menu includes an email address where visitors can give feedback about their food. \n",
    "\n",
    "The manager wants you to create a tool that automatically sends him all the negative reviews so he can fix them, while automatically sending all the positive reviews to the owner, so the manager can ask for a raise. \n",
    "\n",
    "You will first build a model to distinguish positive reviews from negative reviews using Yelp reviews because these reviews include a rating with each review. Your data consists of the text body of each review along with the star rating. Ratings with 1-2 stars count as \"negative\", and ratings with 4-5 stars are \"positive\". Ratings with 3 stars are \"neutral\" and have been dropped from the data.\n",
    "\n",
    "Let's get started. First, run the next code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c48ffd",
   "metadata": {
    "papermill": {
     "duration": 0.014659,
     "end_time": "2021-11-09T00:09:48.802565",
     "exception": false,
     "start_time": "2021-11-09T00:09:48.787906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 1: Evaluate the Approach\n",
    "\n",
    "Is there anything about this approach that concerns you? After you've thought about it, run the function below to see one point of view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f22857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set up code checking\n",
    "# from learntools.core import binder\n",
    "# binder.bind(globals())\n",
    "# from learntools.nlp.ex2 import *\n",
    "# print(\"\\nSetup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "184c53b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:09:48.842432Z",
     "iopub.status.busy": "2021-11-09T00:09:48.841368Z",
     "iopub.status.idle": "2021-11-09T00:09:48.846637Z",
     "shell.execute_reply": "2021-11-09T00:09:48.847324Z"
    },
    "papermill": {
     "duration": 0.029967,
     "end_time": "2021-11-09T00:09:48.847543",
     "exception": false,
     "start_time": "2021-11-09T00:09:48.817576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"questionId\": \"1_EvaluateFeedbackFormApproach\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> Any way of setting up an ML problem will have multiple strengths and weaknesses.  So you may have thought of different issues than listed here.\n",
       "\n",
       "The strength of this approach is that it allows you to distinguish positive email messages from negative emails even though you don't have historical emails that you have labeled as positive or negative.\n",
       "\n",
       "The weakness of this approach is that emails may be systematically different from Yelp reviews in ways that make your model less accurate. For example, customers might generally use different words or slang in emails, and the model based on Yelp reviews won't have seen these words.\n",
       "\n",
       "If you wanted to see how serious this issue is, you could compare word frequencies between the two sources. In practice, manually reading a few emails from each source may be enough to see if it's a serious issue. \n",
       "\n",
       "If you wanted to do something fancier, you could create a dataset that contains both Yelp reviews and emails and see whether a model can tell a reviews source from the text content. Ideally, you'd like to find that model didn't perform well, because it would mean your data sources are similar. That approach seems unnecessarily complex here."
      ],
      "text/plain": [
       "Solution: Any way of setting up an ML problem will have multiple strengths and weaknesses.  So you may have thought of different issues than listed here.\n",
       "\n",
       "The strength of this approach is that it allows you to distinguish positive email messages from negative emails even though you don't have historical emails that you have labeled as positive or negative.\n",
       "\n",
       "The weakness of this approach is that emails may be systematically different from Yelp reviews in ways that make your model less accurate. For example, customers might generally use different words or slang in emails, and the model based on Yelp reviews won't have seen these words.\n",
       "\n",
       "If you wanted to see how serious this issue is, you could compare word frequencies between the two sources. In practice, manually reading a few emails from each source may be enough to see if it's a serious issue. \n",
       "\n",
       "If you wanted to do something fancier, you could create a dataset that contains both Yelp reviews and emails and see whether a model can tell a reviews source from the text content. Ideally, you'd like to find that model didn't perform well, because it would mean your data sources are similar. That approach seems unnecessarily complex here."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check your answer (Run this code cell to receive credit!)\n",
    "# step_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7678e7",
   "metadata": {
    "papermill": {
     "duration": 0.015306,
     "end_time": "2021-11-09T00:09:48.879105",
     "exception": false,
     "start_time": "2021-11-09T00:09:48.863799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 2: Review Data and Create the model\n",
    "\n",
    "Moving forward with your plan, you'll need to load the data. Here's some basic code to load data and split it into a training and validation set. Run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52ca607e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:09:48.913273Z",
     "iopub.status.busy": "2021-11-09T00:09:48.912650Z",
     "iopub.status.idle": "2021-11-09T00:09:49.282264Z",
     "shell.execute_reply": "2021-11-09T00:09:49.282787Z"
    },
    "papermill": {
     "duration": 0.388348,
     "end_time": "2021-11-09T00:09:49.282956",
     "exception": false,
     "start_time": "2021-11-09T00:09:48.894608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(csv_file, split=0.9):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Shuffle data\n",
    "    train_data = data.sample(frac=1, random_state=7)\n",
    "    \n",
    "    texts = train_data.text.values\n",
    "    labels = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)}\n",
    "              for y in train_data.sentiment.values]\n",
    "    split = int(len(train_data) * split)\n",
    "    \n",
    "    train_labels = [{\"cats\": labels} for labels in labels[:split]]\n",
    "    val_labels = [{\"cats\": labels} for labels in labels[split:]]\n",
    "    \n",
    "    return texts[:split], train_labels, texts[split:], val_labels\n",
    "\n",
    "train_texts, train_labels, val_texts, val_labels = load_data('yelp_ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa19dd3",
   "metadata": {
    "papermill": {
     "duration": 0.015545,
     "end_time": "2021-11-09T00:09:49.314531",
     "exception": false,
     "start_time": "2021-11-09T00:09:49.298986",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You will use this training data to build a model. The code to build the model is the same as what you saw in the tutorial. So that is copied below for you.\n",
    "\n",
    "First, run the cell below to look at a couple elements from your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00cb1cdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:09:49.351576Z",
     "iopub.status.busy": "2021-11-09T00:09:49.350731Z",
     "iopub.status.idle": "2021-11-09T00:09:49.354291Z",
     "shell.execute_reply": "2021-11-09T00:09:49.354776Z"
    },
    "papermill": {
     "duration": 0.024579,
     "end_time": "2021-11-09T00:09:49.354950",
     "exception": false,
     "start_time": "2021-11-09T00:09:49.330371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts from training data\n",
      "------\n",
      "[\"Some of the best sushi I've ever had....and I come from the East Coast.  Unreal toro, have some of it's available.\"\n",
      " \"One of the best burgers I've ever had and very well priced. I got the tortilla burger and is was delicious especially with there tortilla soup!\"]\n",
      "\n",
      "Labels from training data\n",
      "------\n",
      "[{'cats': {'POSITIVE': True, 'NEGATIVE': False}}, {'cats': {'POSITIVE': True, 'NEGATIVE': False}}]\n"
     ]
    }
   ],
   "source": [
    "print('Texts from training data\\n------')\n",
    "print(train_texts[:2])\n",
    "print('\\nLabels from training data\\n------')\n",
    "print(train_labels[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e3e81",
   "metadata": {
    "papermill": {
     "duration": 0.016058,
     "end_time": "2021-11-09T00:09:49.390259",
     "exception": false,
     "start_time": "2021-11-09T00:09:49.374201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "But because your data is different, there are **two lines in the modeling code cell that you'll need to change.** Can you figure out what they are? \n",
    "\n",
    "If you're not sure, take a second look at the data, and pay particular attention to the labels that should be fed to the text classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa3145d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:09:49.425759Z",
     "iopub.status.busy": "2021-11-09T00:09:49.425177Z",
     "iopub.status.idle": "2021-11-09T00:09:49.656137Z",
     "shell.execute_reply": "2021-11-09T00:09:49.656593Z"
    },
    "papermill": {
     "duration": 0.250201,
     "end_time": "2021-11-09T00:09:49.656753",
     "exception": false,
     "start_time": "2021-11-09T00:09:49.406552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Create an empty model\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "# Add the TextCategorizer to the empty model\n",
    "textcat = nlp.add_pipe('textcat')\n",
    "\n",
    "# Add labels to text classifier\n",
    "textcat.add_label(\"ham\")\n",
    "textcat.add_label(\"spam\")\n",
    "\n",
    "# Check your answer\n",
    "# step_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c7b5612",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:09:49.694363Z",
     "iopub.status.busy": "2021-11-09T00:09:49.693526Z",
     "iopub.status.idle": "2021-11-09T00:09:49.697056Z",
     "shell.execute_reply": "2021-11-09T00:09:49.696620Z"
    },
    "papermill": {
     "duration": 0.023704,
     "end_time": "2021-11-09T00:09:49.697224",
     "exception": false,
     "start_time": "2021-11-09T00:09:49.673520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#step_2.hint()\n",
    "#step_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14602f2",
   "metadata": {
    "papermill": {
     "duration": 0.016611,
     "end_time": "2021-11-09T00:09:49.730871",
     "exception": false,
     "start_time": "2021-11-09T00:09:49.714260",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 3: Train Function\n",
    "\n",
    "Implement a function `train` that updates a model with training data. Most of this is general data munging, which we've filled in for you. \n",
    "\n",
    "Just add the one line of code necessary to update your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc7443c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:09:49.768627Z",
     "iopub.status.busy": "2021-11-09T00:09:49.767672Z",
     "iopub.status.idle": "2021-11-09T00:10:08.318565Z",
     "shell.execute_reply": "2021-11-09T00:10:08.317945Z"
    },
    "papermill": {
     "duration": 18.570882,
     "end_time": "2021-11-09T00:10:08.318706",
     "exception": false,
     "start_time": "2021-11-09T00:09:49.747824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from spacy.util import minibatch\n",
    "from spacy.training.example import Example\n",
    "\n",
    "def train(model, train_data, optimizer, batch_size=8):\n",
    "    losses = {}\n",
    "    random.seed(1)\n",
    "    random.shuffle(train_data)\n",
    "    \n",
    "    # train_data is a list of tuples [(text0, label0), (text1, label1), ...]\n",
    "    for batch in minibatch(train_data, size=batch_size):\n",
    "        # Split batch into text and labels\n",
    "        for text, labels in batch:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, labels)\n",
    "            # Update model with texts and labels\n",
    "            nlp.update([example], sgd=optimizer, losses=losses)\n",
    "        \n",
    "    return losses\n",
    "\n",
    "# Check your answer\n",
    "# step_3.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92915197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:10:08.361929Z",
     "iopub.status.busy": "2021-11-09T00:10:08.361303Z",
     "iopub.status.idle": "2021-11-09T00:10:08.363668Z",
     "shell.execute_reply": "2021-11-09T00:10:08.363055Z"
    },
    "papermill": {
     "duration": 0.025058,
     "end_time": "2021-11-09T00:10:08.363799",
     "exception": false,
     "start_time": "2021-11-09T00:10:08.338741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#step_3.hint()\n",
    "#step_3.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "774a3f69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:10:08.413012Z",
     "iopub.status.busy": "2021-11-09T00:10:08.412044Z",
     "iopub.status.idle": "2021-11-09T00:10:27.718141Z",
     "shell.execute_reply": "2021-11-09T00:10:27.717652Z"
    },
    "papermill": {
     "duration": 19.335386,
     "end_time": "2021-11-09T00:10:27.718287",
     "exception": false,
     "start_time": "2021-11-09T00:10:08.382901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10019.25\n"
     ]
    }
   ],
   "source": [
    "# Fix seed for reproducibility\n",
    "spacy.util.fix_random_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "# This may take a while to run!\n",
    "optimizer = nlp.begin_training()\n",
    "train_data = list(zip(train_texts, train_labels))\n",
    "losses = train(nlp, train_data, optimizer)\n",
    "print(losses['textcat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b581a08",
   "metadata": {
    "papermill": {
     "duration": 0.019127,
     "end_time": "2021-11-09T00:10:27.757249",
     "exception": false,
     "start_time": "2021-11-09T00:10:27.738122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can try this slightly trained model on some example text and look at the probabilities assigned to each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24538bb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:10:27.799928Z",
     "iopub.status.busy": "2021-11-09T00:10:27.799329Z",
     "iopub.status.idle": "2021-11-09T00:10:27.806457Z",
     "shell.execute_reply": "2021-11-09T00:10:27.805959Z"
    },
    "papermill": {
     "duration": 0.029657,
     "end_time": "2021-11-09T00:10:27.806595",
     "exception": false,
     "start_time": "2021-11-09T00:10:27.776938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ham': 0.5, 'spam': 0.5}\n"
     ]
    }
   ],
   "source": [
    "text = \"This tea cup was full of holes. Do not recommend.\"\n",
    "doc = nlp(text)\n",
    "print(doc.cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8343bc6",
   "metadata": {
    "papermill": {
     "duration": 0.019765,
     "end_time": "2021-11-09T00:10:27.846545",
     "exception": false,
     "start_time": "2021-11-09T00:10:27.826780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "These probabilities look reasonable. Now you should turn them into an actual prediction.\n",
    "\n",
    "# Step 4: Making Predictions\n",
    "\n",
    "Implement a function `predict` that predicts the sentiment of text examples. \n",
    "- First, tokenize the texts using `nlp.tokenizer()`. \n",
    "- Then, pass those docs to the TextCategorizer which you can get from `nlp.get_pipe()`. \n",
    "- Use the `textcat.predict()` method to get scores for each document, then choose the class with the highest score (probability) as the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "946aad2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:10:27.892391Z",
     "iopub.status.busy": "2021-11-09T00:10:27.891465Z",
     "iopub.status.idle": "2021-11-09T00:10:45.023744Z",
     "shell.execute_reply": "2021-11-09T00:10:45.023280Z"
    },
    "papermill": {
     "duration": 17.157224,
     "end_time": "2021-11-09T00:10:45.023878",
     "exception": false,
     "start_time": "2021-11-09T00:10:27.866654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-11-09 00:10:28,051] [INFO] Created vocabulary\n",
      "[2021-11-09 00:10:28,054] [INFO] Finished initializing nlp object\n"
     ]
    },
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 2, \"failureMessage\": \"\", \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"4_PredictFunction\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#cc3333\">Incorrect</span>"
      ],
      "text/plain": [
       "Incorrect"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict(nlp, texts): \n",
    "    # Use the model's tokenizer to tokenize each input text\n",
    "    docs = ____\n",
    "    \n",
    "    # Use textcat to get the scores for each doc\n",
    "    ____\n",
    "    \n",
    "    # From the scores, find the class with the highest score/probability\n",
    "    predicted_class = ____\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Check your answer\n",
    "step_4.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "231134da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:10:45.070275Z",
     "iopub.status.busy": "2021-11-09T00:10:45.069685Z",
     "iopub.status.idle": "2021-11-09T00:10:45.072196Z",
     "shell.execute_reply": "2021-11-09T00:10:45.072635Z"
    },
    "papermill": {
     "duration": 0.027487,
     "end_time": "2021-11-09T00:10:45.072790",
     "exception": false,
     "start_time": "2021-11-09T00:10:45.045303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#step_4.hint()\n",
    "#step_4.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41e0d56d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:10:45.119858Z",
     "iopub.status.busy": "2021-11-09T00:10:45.119217Z",
     "iopub.status.idle": "2021-11-09T00:10:45.141392Z",
     "shell.execute_reply": "2021-11-09T00:10:45.141926Z"
    },
    "papermill": {
     "duration": 0.047042,
     "end_time": "2021-11-09T00:10:45.142136",
     "exception": false,
     "start_time": "2021-11-09T00:10:45.095094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zip argument #1 must support iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/3658977118.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{textcat.labels[p]}: {t} \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: zip argument #1 must support iteration"
     ]
    }
   ],
   "source": [
    "texts = val_texts[34:38]\n",
    "predictions = predict(nlp, texts)\n",
    "\n",
    "for p, t in zip(predictions, texts):\n",
    "    print(f\"{textcat.labels[p]}: {t} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07727d56",
   "metadata": {
    "papermill": {
     "duration": 0.023215,
     "end_time": "2021-11-09T00:10:45.188853",
     "exception": false,
     "start_time": "2021-11-09T00:10:45.165638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It looks like your model is working well after going through the data just once. However you need to calculate some metric for the model's performance on the hold-out validation data.\n",
    "\n",
    "# Step 5: Evaluate The Model\n",
    "\n",
    "Implement a function that evaluates a `TextCategorizer` model. This function `evaluate` takes a model along with texts and labels. It returns the accuracy of the model, which is the number of correct predictions divided by all predictions.\n",
    "\n",
    "First, use the `predict` method you wrote earlier to get the predicted class for each text in `texts`. Then, find where the predicted labels match the true \"gold-standard\" labels and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd0ee2f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:10:45.236182Z",
     "iopub.status.busy": "2021-11-09T00:10:45.235322Z",
     "iopub.status.idle": "2021-11-09T00:11:02.469788Z",
     "shell.execute_reply": "2021-11-09T00:11:02.469288Z"
    },
    "papermill": {
     "duration": 17.259066,
     "end_time": "2021-11-09T00:11:02.469934",
     "exception": false,
     "start_time": "2021-11-09T00:10:45.210868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-11-09 00:10:45,392] [INFO] Created vocabulary\n",
      "[2021-11-09 00:10:45,393] [INFO] Finished initializing nlp object\n"
     ]
    },
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 2, \"failureMessage\": \"\", \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"5_EvaluateFunction\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#cc3333\">Incorrect</span>"
      ],
      "text/plain": [
       "Incorrect"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate(model, texts, labels):\n",
    "    \"\"\" Returns the accuracy of a TextCategorizer model. \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        model: ScaPy model with a TextCategorizer\n",
    "        texts: Text samples, from load_data function\n",
    "        labels: True labels, from load_data function\n",
    "    \n",
    "    \"\"\"\n",
    "    # Get predictions from textcat model (using your predict method)\n",
    "    predicted_class = ____\n",
    "    \n",
    "    # From labels, get the true class as a list of integers (POSITIVE -> 1, NEGATIVE -> 0)\n",
    "    true_class = ____\n",
    "    \n",
    "    # A boolean or int array indicating correct predictions\n",
    "    correct_predictions = ____\n",
    "    \n",
    "    # The accuracy, number of correct predictions divided by all predictions\n",
    "    accuracy = ____\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Check your answer\n",
    "step_5.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69bda513",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:11:02.520923Z",
     "iopub.status.busy": "2021-11-09T00:11:02.520325Z",
     "iopub.status.idle": "2021-11-09T00:11:02.523979Z",
     "shell.execute_reply": "2021-11-09T00:11:02.523493Z"
    },
    "papermill": {
     "duration": 0.029657,
     "end_time": "2021-11-09T00:11:02.524144",
     "exception": false,
     "start_time": "2021-11-09T00:11:02.494487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#step_5.hint()\n",
    "#step_5.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c94c7c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:11:02.575021Z",
     "iopub.status.busy": "2021-11-09T00:11:02.574428Z",
     "iopub.status.idle": "2021-11-09T00:11:02.595345Z",
     "shell.execute_reply": "2021-11-09T00:11:02.595827Z"
    },
    "papermill": {
     "duration": 0.048331,
     "end_time": "2021-11-09T00:11:02.595994",
     "exception": false,
     "start_time": "2021-11-09T00:11:02.547663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to PlaceholderValue.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/318911064.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy: {accuracy:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to PlaceholderValue.__format__"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate(nlp, val_texts, val_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09759e8",
   "metadata": {
    "papermill": {
     "duration": 0.024965,
     "end_time": "2021-11-09T00:11:02.645770",
     "exception": false,
     "start_time": "2021-11-09T00:11:02.620805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "With the functions implemented, you can train and evaluate in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19fbb57d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:11:02.697190Z",
     "iopub.status.busy": "2021-11-09T00:11:02.696559Z",
     "iopub.status.idle": "2021-11-09T00:11:17.145291Z",
     "shell.execute_reply": "2021-11-09T00:11:17.145781Z"
    },
    "papermill": {
     "duration": 14.475682,
     "end_time": "2021-11-09T00:11:17.145963",
     "exception": false,
     "start_time": "2021-11-09T00:11:02.670281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'textcat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/3352740945.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loss: {losses['textcat']:.3f} \\t Accuracy: {accuracy:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'textcat'"
     ]
    }
   ],
   "source": [
    "# This may take a while to run!\n",
    "n_iters = 5\n",
    "for i in range(n_iters):\n",
    "    losses = train(nlp, train_data, optimizer)\n",
    "    accuracy = evaluate(nlp, val_texts, val_labels)\n",
    "    print(f\"Loss: {losses['textcat']:.3f} \\t Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65be1112",
   "metadata": {
    "papermill": {
     "duration": 0.023532,
     "end_time": "2021-11-09T00:11:17.193774",
     "exception": false,
     "start_time": "2021-11-09T00:11:17.170242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 6: Keep Improving\n",
    "\n",
    "You've built the necessary components to train a text classifier with spaCy. What could you do further to optimize the model?\n",
    "\n",
    "Run the next line to check your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "780452a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:11:17.246415Z",
     "iopub.status.busy": "2021-11-09T00:11:17.245474Z",
     "iopub.status.idle": "2021-11-09T00:11:17.252048Z",
     "shell.execute_reply": "2021-11-09T00:11:17.252619Z"
    },
    "papermill": {
     "duration": 0.034214,
     "end_time": "2021-11-09T00:11:17.252777",
     "exception": false,
     "start_time": "2021-11-09T00:11:17.218563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"questionId\": \"6_ModelOptimizationQuestion\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc99\">Solution:</span> Answer: There are various hyperparameters to work with here. The biggest one is the TextCategorizer architecture. You used the simplest model which trains faster but likely has worse performance than the CNN and ensemble models. "
      ],
      "text/plain": [
       "Solution: Answer: There are various hyperparameters to work with here. The biggest one is the TextCategorizer architecture. You used the simplest model which trains faster but likely has worse performance than the CNN and ensemble models. "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check your answer (Run this code cell to receive credit!)\n",
    "step_6.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9cf325",
   "metadata": {
    "papermill": {
     "duration": 0.031679,
     "end_time": "2021-11-09T00:11:17.313608",
     "exception": false,
     "start_time": "2021-11-09T00:11:17.281929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Keep Going\n",
    "\n",
    "The next step is a big one. See how you can **[represent tokens as vectors that describe their meaning](https://www.kaggle.com/matleonard/word-vectors)**, and plug those into your machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf475b8",
   "metadata": {
    "papermill": {
     "duration": 0.02473,
     "end_time": "2021-11-09T00:11:17.363471",
     "exception": false,
     "start_time": "2021-11-09T00:11:17.338741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/natural-language-processing/discussion) to chat with other learners.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nlp': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 109.563623,
   "end_time": "2021-11-09T00:11:20.218288",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-09T00:09:30.654665",
   "version": "2.3.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2cbea589eae7a3a46a0a358816519b81140f2c5f52c17736af325f4b6c61841"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
